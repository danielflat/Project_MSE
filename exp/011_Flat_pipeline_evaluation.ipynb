{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:43:43.616117Z",
     "start_time": "2024-07-17T18:43:37.835931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from ranker.ranker import Ranker"
   ],
   "id": "8db907afa5099773",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielwps/Documents/Private/Github/Project_MSE/venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:44:06.615151Z",
     "start_time": "2024-07-17T18:43:46.367780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# might take long right now because the database is very big nowadays. Just play with the sleep parameter if you want to.\n",
    "os.system(\"\"\"\n",
    "    docker compose down;\n",
    "    docker compose up -d --build db;\n",
    "    sleep 15;\n",
    "    \"\"\")"
   ],
   "id": "701371f40d7c4c26",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container project_mse-db-1  Stopping\n",
      " Container project_mse-db-1  Stopped\n",
      " Container project_mse-db-1  Removing\n",
      " Container project_mse-db-1  Removed\n",
      " Network project_mse_default  Removing\n",
      " Network project_mse_default  Removed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [db internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 122B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [db internal] load metadata for docker.io/library/postgres:latest\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [db internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [db 1/2] FROM docker.io/library/postgres:latest\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [db internal] load build context\n",
      "#5 transferring context: 256.02MB 2.2s done\n",
      "#5 DONE 2.2s\n",
      "\n",
      "#4 [db 1/2] FROM docker.io/library/postgres:latest\n",
      "#4 CACHED\n",
      "\n",
      "#6 [db 2/2] COPY dump.sql /docker-entrypoint-initdb.d/\n",
      "#6 DONE 0.5s\n",
      "\n",
      "#7 [db] exporting to image\n",
      "#7 exporting layers\n",
      "#7 exporting layers 0.9s done\n",
      "#7 writing image sha256:adc459849458a6171d192047e67798273aa6b38edb127bdebd37555d89b215ea\n",
      "#7 writing image sha256:adc459849458a6171d192047e67798273aa6b38edb127bdebd37555d89b215ea done\n",
      "#7 naming to docker.io/library/project_mse-db done\n",
      "#7 DONE 0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Network project_mse_default  Creating\n",
      " Network project_mse_default  Created\n",
      " Container project_mse-db-1  Creating\n",
      " Container project_mse-db-1  Created\n",
      " Container project_mse-db-1  Starting\n",
      " Container project_mse-db-1  Started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:44:27.663598Z",
     "start_time": "2024-07-17T18:44:10.002355Z"
    }
   },
   "source": [
    "ranker = Ranker()\n",
    "tokenizer = ranker.tokenizer\n",
    "documentRepository = ranker.documentRepository"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC: Connected to the db. Now you can go and build the best search engine around!\n",
      "Loading Documents first...\n",
      "All documents loaded.\n",
      "Now we load TF and IDF\n",
      "TF and IDF loaded.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If it gets problematic that the db does not work, just wait a bit. Since the db might be big, docker needs some time. Wait 10 and execute it again. ",
   "id": "c27ea77949781e2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:44:37.477259Z",
     "start_time": "2024-07-17T18:44:37.472498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_docs = ranker.all_docs\n",
    "len(all_docs)"
   ],
   "id": "231351053cf38039",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:45:41.981547Z",
     "start_time": "2024-07-17T18:45:41.358321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Tübingen food\"\n",
    "index_length = len(all_docs)  # use len(all_docs) to evaluate on full index OR a number, e.g. 1000, to only evaluate on the first 1000 documents\n",
    "\n",
    "# prepare index. \n",
    "trun_docs = all_docs[:index_length]\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Ranking is starting\")\n",
    "\n",
    "query_result = ranker.rank_query(query, documents=trun_docs, n=100)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Query: {query} , Number of documents: {index_length}, Time required: {end_time - start_time} seconds\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Rank: {i}, Score: {query_result.scores[i]}, URL: {query_result.documents[i].url}\")"
   ],
   "id": "b6f5d5533cb9cfbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking is starting\n",
      "Query: Tübingen food , Number of documents: 6355, Time required: 0.6190938949584961 seconds\n",
      "Rank: 0, Score: 6.007689952850342, URL: https://www.my-stuwe.de/en//refectory/allergene-zusatzstoffe/\n",
      "Rank: 1, Score: 6.007689952850342, URL: https://www.my-stuwe.de/en//refectory/allergens/\n",
      "Rank: 2, Score: 6.007689952850342, URL: https://www.my-stuwe.de/en/refectory/allergens/\n",
      "Rank: 3, Score: 6.007689952850342, URL: https://www.my-stuwe.de/en//refectory/allergens\n",
      "Rank: 4, Score: 5.859803199768066, URL: https://www.my-stuwe.de/en/refectory/co2/\n",
      "Rank: 5, Score: 5.635893821716309, URL: https://allevents.in/tubingen?ref=mmenu\n",
      "Rank: 6, Score: 5.626857757568359, URL: https://allevents.in/tubingen\n",
      "Rank: 7, Score: 5.608704566955566, URL: https://www.my-stuwe.de/en/presse/co2-label/\n",
      "Rank: 8, Score: 5.601853370666504, URL: https://www.my-stuwe.de/en/co2-label/\n",
      "Rank: 9, Score: 5.592313766479492, URL: http://www.historicgermany.travel/germany-map/\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a8e4a1cd5b506d9b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
