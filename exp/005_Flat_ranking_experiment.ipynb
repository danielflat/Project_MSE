{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import spacy\n",
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from db.DocumentRepository import DocumentRepository"
   ],
   "id": "48197ab7438c4377",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.system(\"\"\"\n",
    "    docker compose down;\n",
    "    docker compose up -d --build db;\n",
    "    \"\"\")"
   ],
   "id": "bf836a8f1e0ddca",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Ranker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.documentRepository = DocumentRepository()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def rank_query(self, query):\n",
    "        tokenized_query = self.tokenizer.encode(query)\n",
    "        documents_vectors = self.documentRepository.getEncodedTextOfAllDocuments()\n",
    "        bm25_scores = self.rank_BM25(tokenized_query, documents_vectors)\n",
    "        return bm25_scores\n",
    "\n",
    "    def _compute_tf(self, token, doc_vec):\n",
    "        return np.sum(doc_vec == token)\n",
    "\n",
    "    def _compute_idf(self, documents: list[np.array]):\n",
    "        N = len(documents)\n",
    "        idf = {}\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                if word in idf:\n",
    "                    idf[word] += 1\n",
    "                else:\n",
    "                    idf[word] = 1\n",
    "        for word, count in idf.items():\n",
    "            idf[word] = np.log(((N + 1) / (count + 0.5)) + 1)\n",
    "        return idf\n",
    "\n",
    "    def rank_BM25(self, tokenized_query: list[int], documents_vectors: dict[str, np.array], k=1.5, b=0.75):\n",
    "        \"\"\"\n",
    "        Calculate the Okapi Best Model 25 scores for a set of documents given a query.\n",
    "        The BM25 score for a document D given a query Q is calculated as:\n",
    "        BM25(D, Q) = Σ [ IDF(q_i) * (f(q_i, D) * (k + 1)) / (f(q_i, D) + k * (1 - b + b * (|D| / avgdl))) ]\n",
    "        \n",
    "        Note: The BM25 score of a document is <= 0 but can be > 1.\n",
    "        \n",
    "        Where:\n",
    "            - q_i: the i-th term in the query Q.\n",
    "            - f(q_i, D): term frequency of q_i in document D.\n",
    "            - |D|: length of document D.\n",
    "            - avgdl: average document length in the corpus.\n",
    "            - k: controls the term frequency saturation. Typical values range from 1.2 to 2.0.\n",
    "            - b: controls the length normalization. Typical values range from 0.75 to 1.0.\n",
    "            - IDF(q_i): inverse document frequency of the term q_i.\n",
    "    \n",
    "        Parameters:\n",
    "            tokenized_query (list of int): list of tokens.\n",
    "            documents_vectors (dict of (str, np.array)): contains for each url the encoded np.array\n",
    "            k (float, optional): term frequency saturation parameter. Default is 1.5.\n",
    "            b (float, optional): length normalization parameter. Default is 0.75.\n",
    "    \n",
    "        Returns:\n",
    "            Dict[str, float]: a dictionary where keys are the urls and values are the corresponding BM25 scores.\n",
    "        \"\"\"\n",
    "        # Compute the number of documents\n",
    "        n = len(documents_vectors)\n",
    "\n",
    "        # TODO: Can be precomputed ------\n",
    "        # Compute average document length\n",
    "        vectors_list = list(documents_vectors.values())\n",
    "        avg_doc_len = np.mean([len(i) for i in vectors_list])\n",
    "\n",
    "        # Compute IDF for all terms in the corpus\n",
    "        idf = self._compute_idf(vectors_list)\n",
    "        # --------\n",
    "\n",
    "        scores = {}\n",
    "\n",
    "        # Compute term frequency IF(q, d)\n",
    "        for url, doc_vec in documents_vectors.items():\n",
    "            score = 0\n",
    "            doc_length = len(doc_vec)\n",
    "\n",
    "            for token in tokenized_query:\n",
    "                tf = self._compute_tf(token, doc_vec)\n",
    "                numerator = (idf.get(token, np.log(\n",
    "                    n + 1))  # assuming for a new word to have a high IDF-value because it's \"rare\".\n",
    "                             * tf * (k - 1))  # frequency counting penalty\n",
    "                denominator = tf + k * (1 - b + b * (doc_length / avg_doc_len))  # length norm\n",
    "                score += numerator / denominator\n",
    "\n",
    "            scores[url] = score\n",
    "\n",
    "        sorted_scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        return sorted_scores\n",
    "\n",
    "\n",
    "ranker = Ranker()"
   ],
   "id": "833d2bbfdc547349",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test 1\n",
    "\n",
    "easy example using a small corpus"
   ],
   "id": "5c3378542a0fcf9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Adjust them for testing \n",
    "query = \"quick fox\"\n",
    "corpus = {0: \"the quick brown fox\",\n",
    "          1: \"jumps over the lazy dog\",\n",
    "          2: \"lorem ipsum dolor sit amet\",\n",
    "          3: \"consectetur adipiscing elit\",\n",
    "          4: \"the quick brown wolf\",\n",
    "          }\n",
    "\n",
    "corpus_vectorizes = {}\n",
    "for i, sentence in corpus.items():\n",
    "    corpus_vectorizes[i] = np.array(ranker.tokenizer.encode(sentence, add_special_tokens=False))\n",
    "\n",
    "tokenized_query = np.array(ranker.tokenizer.encode(query, add_special_tokens=False))\n",
    "\n",
    "# Compute BM25 scores\n",
    "scores = ranker.rank_BM25(tokenized_query, corpus_vectorizes)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Print scores\n",
    "for doc, score in scores.items():\n",
    "    print(f\"Document: {doc} => BM25 Score: {score}\")"
   ],
   "id": "31e6d9ee98e44bf6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test 2\n",
    "\n",
    "using the whole db corpus"
   ],
   "id": "bf0e7374297b22d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"Tübing\"  # Change this for testing\n",
    "corpus = ranker.documentRepository.getEncodedTextOfAllDocuments()\n",
    "\n",
    "# Compute BM25 scores\n",
    "scores = ranker.rank_BM25(np.array(ranker.tokenizer.encode(query, add_special_tokens=False)), corpus)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Print scores\n",
    "for doc, score in scores.items():\n",
    "    print(f\"Document: {doc} => BM25 Score: {score}\")"
   ],
   "id": "d3228bd3067a9cdd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test 3\n",
    "\n",
    "This experiment is using the library \"rank_mb25\" to compute BM25."
   ],
   "id": "8d374db1353be786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import tiktoken\n",
    "\n",
    "# # Example documents and query\n",
    "# documents = [\n",
    "#     \"The quick brown fox jumps over the lazy dog\",\n",
    "#     \"Never jump over the lazy dog quickly\",\n",
    "#     \"A fast fox and a lazy dog in a park\",\n",
    "# ]\n",
    "documents = [\"the quick brown fox\",\n",
    "             \"jumps over the lazy dog\",\n",
    "             \"lorem ipsum dolor sit amet\",\n",
    "             \"consectetur adipiscing elit\",\n",
    "             \"the quick brown wolf\"]\n",
    "query = \"quick fox\"\n",
    "\n",
    "# Tokenize documents and query\n",
    "tokenized_docs = [ranker.tokenizer.encode(doc) for doc in documents]\n",
    "tokenized_query = ranker.tokenizer.encode(query)\n",
    "\n",
    "# BM25\n",
    "bm25 = BM25Okapi(tokenized_docs)\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "bm25_scores"
   ],
   "id": "2faf83b90aab0e0b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.system(\"\"\"\n",
    "    docker compose down;\n",
    "    \"\"\")"
   ],
   "id": "9429fb15a90764ae",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
