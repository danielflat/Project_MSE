{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:14:30.242939Z",
     "start_time": "2024-07-14T17:14:25.587627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import spacy\n",
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from db.DocumentRepository import DocumentRepository\n"
   ],
   "id": "48197ab7438c4377",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:14:31.785860Z",
     "start_time": "2024-07-14T17:14:30.245635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.system(\"\"\"\n",
    "    docker compose down;\n",
    "    docker compose up -d --build db;\n",
    "    \"\"\")"
   ],
   "id": "bf836a8f1e0ddca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container project_mse-db-1  Stopping\n",
      " Container project_mse-db-1  Stopped\n",
      " Container project_mse-db-1  Removing\n",
      " Container project_mse-db-1  Removed\n",
      " Network project_mse_default  Removing\n",
      " Network project_mse_default  Removed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [db internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 122B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [db internal] load metadata for docker.io/library/postgres:latest\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [db internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [db 1/2] FROM docker.io/library/postgres:latest\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [db internal] load build context\n",
      "#5 transferring context: 69B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [db 2/2] COPY dump.sql /docker-entrypoint-initdb.d/\n",
      "#6 CACHED\n",
      "\n",
      "#7 [db] exporting to image\n",
      "#7 exporting layers done\n",
      "#7 writing image sha256:4309df92e6a4a6651b884dd8eea6e932d63c0bf202ba691fa3819b60a26bbc2b done\n",
      "#7 naming to docker.io/library/project_mse-db done\n",
      "#7 DONE 0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Network project_mse_default  Creating\n",
      " Network project_mse_default  Created\n",
      " Container project_mse-db-1  Creating\n",
      " Container project_mse-db-1  Created\n",
      " Container project_mse-db-1  Starting\n",
      " Container project_mse-db-1  Started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:14:32.131803Z",
     "start_time": "2024-07-14T17:14:31.789417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Ranker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.documentRepository = DocumentRepository()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def rank_query(self, query):\n",
    "        tokenized_query = self.tokenizer.encode(query)\n",
    "        documents_vectors = self.documentRepository.getEncodedTextOfAllDocuments()\n",
    "        bm25_scores = self.rank_BM25(tokenized_query, documents_vectors)\n",
    "        return bm25_scores\n",
    "\n",
    "    def _compute_tf(self, token, doc_vec):\n",
    "        return np.sum(doc_vec == token)\n",
    "\n",
    "    def _compute_idf(self, documents: list[np.array]):\n",
    "        N = len(documents)\n",
    "        idf = {}\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                if word in idf:\n",
    "                    idf[word] += 1\n",
    "                else:\n",
    "                    idf[word] = 1\n",
    "        for word, count in idf.items():\n",
    "            idf[word] = np.log(((N + 1) / (count + 0.5)) + 1)\n",
    "        return idf\n",
    "\n",
    "    def rank_BM25(self, tokenized_query: list[int], documents_vectors: dict[str, np.array], k=1.5, b=0.75):\n",
    "        \"\"\"\n",
    "        Calculate the Okapi Best Model 25 scores for a set of documents given a query.\n",
    "        The BM25 score for a document D given a query Q is calculated as:\n",
    "        BM25(D, Q) = Î£ [ IDF(q_i) * (f(q_i, D) * (k + 1)) / (f(q_i, D) + k * (1 - b + b * (|D| / avgdl))) ]\n",
    "        \n",
    "        Note: The BM25 score of a document is <= 0 but can be > 1.\n",
    "        \n",
    "        Where:\n",
    "            - q_i: the i-th term in the query Q.\n",
    "            - f(q_i, D): term frequency of q_i in document D.\n",
    "            - |D|: length of document D.\n",
    "            - avgdl: average document length in the corpus.\n",
    "            - k: controls the term frequency saturation. Typical values range from 1.2 to 2.0.\n",
    "            - b: controls the length normalization. Typical values range from 0.75 to 1.0.\n",
    "            - IDF(q_i): inverse document frequency of the term q_i.\n",
    "    \n",
    "        Parameters:\n",
    "            tokenized_query (list of int): list of tokens.\n",
    "            documents_vectors (dict of (str, np.array)): contains for each url the encoded np.array\n",
    "            k (float, optional): term frequency saturation parameter. Default is 1.5.\n",
    "            b (float, optional): length normalization parameter. Default is 0.75.\n",
    "    \n",
    "        Returns:\n",
    "            Dict[str, float]: a dictionary where keys are the urls and values are the corresponding BM25 scores.\n",
    "        \"\"\"\n",
    "        # Compute the number of documents\n",
    "        n = len(documents_vectors)\n",
    "\n",
    "        # TODO: Can be precomputed ------\n",
    "        # Compute average document length\n",
    "        vectors_list = list(documents_vectors.values())\n",
    "        avg_doc_len = np.mean([len(i) for i in vectors_list])\n",
    "\n",
    "        # Compute IDF for all terms in the corpus\n",
    "        idf = self._compute_idf(vectors_list)\n",
    "        # --------\n",
    "\n",
    "        scores = {}\n",
    "\n",
    "        # Compute term frequency IF(q, d)\n",
    "        for url, doc_vec in documents_vectors.items():\n",
    "            score = 0\n",
    "            doc_length = len(doc_vec)\n",
    "\n",
    "            for token in tokenized_query:\n",
    "                tf = self._compute_tf(token, doc_vec)\n",
    "                numerator = (idf.get(token, np.log(\n",
    "                    n + 1))  # assuming for a new word to have a high IDF-value because it's \"rare\".\n",
    "                             * tf * (k - 1))  # frequency counting penalty\n",
    "                denominator = tf + k * (1 - b + b * (doc_length / avg_doc_len))  # length norm\n",
    "                score += numerator / denominator\n",
    "\n",
    "            scores[url] = score\n",
    "\n",
    "        sorted_scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        return sorted_scores\n",
    "\n",
    "\n",
    "ranker = Ranker()"
   ],
   "id": "833d2bbfdc547349",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC: Connecting to PostgreSQL did not work. Maybe try to run it again. connection to server at \"localhost\" (::1), port 5432 failed: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test 1\n",
    "\n",
    "easy example using a small corpus"
   ],
   "id": "5c3378542a0fcf9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:14:32.143920Z",
     "start_time": "2024-07-14T17:14:32.135308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust them for testing \n",
    "query = \"the quick brown fox\"\n",
    "corpus = {0: \"the quick brown fox\",\n",
    "          1: \"jumps over the lazy dog\",\n",
    "          2: \"lorem ipsum dolor sit amet\",\n",
    "          3: \"consectetur adipiscing elit\",\n",
    "          4: \"the quick brown wolf\",\n",
    "          }\n",
    "\n",
    "corpus_vectorizes = {}\n",
    "for i, sentence in corpus.items():\n",
    "    corpus_vectorizes[i] = np.array(ranker.tokenizer.encode(sentence, add_special_tokens=False))\n",
    "\n",
    "tokenized_query = np.array(ranker.tokenizer.encode(query, add_special_tokens=False))\n",
    "\n",
    "# Compute BM25 scores\n",
    "scores = ranker.rank_BM25(tokenized_query, corpus_vectorizes)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Print scores\n",
    "for doc, score in scores.items():\n",
    "    print(f\"Document: {doc} => BM25 Score: {score}\")"
   ],
   "id": "31e6d9ee98e44bf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: the quick brown fox\n",
      "Document: 0 => BM25 Score: 1.2163651382350578\n",
      "Document: 4 => BM25 Score: 0.8291319562960261\n",
      "Document: 1 => BM25 Score: 0.22151072834354296\n",
      "Document: 2 => BM25 Score: 0.0\n",
      "Document: 3 => BM25 Score: 0.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test 2\n",
    "\n",
    "using the whole db corpus"
   ],
   "id": "bf0e7374297b22d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T17:14:32.590354Z",
     "start_time": "2024-07-14T17:14:32.146634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"TÃ¼bingen\"  # Change this for testing\n",
    "corpus = ranker.documentRepository.getEncodedTextOfAllDocuments()\n",
    "\n",
    "# Compute BM25 scores\n",
    "scores = ranker.rank_BM25(np.array(ranker.tokenizer.encode(query, add_special_tokens=False)), corpus)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Print scores\n",
    "for doc, score in scores.items():\n",
    "    print(f\"Document: {doc} => BM25 Score: {score}\")"
   ],
   "id": "d3228bd3067a9cdd",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DocumentRepository' object has no attribute 'cursor'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTÃ¼bingen\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# Change this for testing\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m corpus \u001B[38;5;241m=\u001B[39m \u001B[43mranker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdocumentRepository\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetEncodedTextOfAllDocuments\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Compute BM25 scores\u001B[39;00m\n\u001B[1;32m      5\u001B[0m scores \u001B[38;5;241m=\u001B[39m ranker\u001B[38;5;241m.\u001B[39mrank_BM25(np\u001B[38;5;241m.\u001B[39marray(ranker\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mencode(query, add_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)), corpus)\n",
      "File \u001B[0;32m~/Documents/Private/Github/Project_MSE/db/DocumentRepository.py:135\u001B[0m, in \u001B[0;36mDocumentRepository.getEncodedTextOfAllDocuments\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetEncodedTextOfAllDocuments\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, np\u001B[38;5;241m.\u001B[39marray]:\n\u001B[1;32m    132\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m    Encodes the text using BERT tokenizer\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 135\u001B[0m     allDocuments \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadAllDocuments\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m     documents_vectors \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m allDocuments:\n",
      "File \u001B[0;32m~/Documents/Private/Github/Project_MSE/db/DocumentRepository.py:72\u001B[0m, in \u001B[0;36mDocumentRepository.loadAllDocuments\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloadAllDocuments\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[DocumentEntry]:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcursor\u001B[49m\u001B[38;5;241m.\u001B[39mexecute(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM documents\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     73\u001B[0m     rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcursor\u001B[38;5;241m.\u001B[39mfetchall()\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;66;03m# Convert rows to list of TestClass objects\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DocumentRepository' object has no attribute 'cursor'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Test 3\n",
    "\n",
    "This experiment is using the library \"rank_mb25\" to compute BM25."
   ],
   "id": "8d374db1353be786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import tiktoken\n",
    "\n",
    "# # Example documents and query\n",
    "# documents = [\n",
    "#     \"The quick brown fox jumps over the lazy dog\",\n",
    "#     \"Never jump over the lazy dog quickly\",\n",
    "#     \"A fast fox and a lazy dog in a park\",\n",
    "# ]\n",
    "documents = [\"the quick brown fox\",\n",
    "             \"jumps over the lazy dog\",\n",
    "             \"lorem ipsum dolor sit amet\",\n",
    "             \"consectetur adipiscing elit\",\n",
    "             \"the quick brown wolf\"]\n",
    "query = \"quick fox\"\n",
    "\n",
    "# Tokenize documents and query\n",
    "tokenized_docs = [ranker.tokenizer.encode(doc) for doc in documents]\n",
    "tokenized_query = ranker.tokenizer.encode(query)\n",
    "\n",
    "# BM25\n",
    "bm25 = BM25Okapi(tokenized_docs)\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "bm25_scores"
   ],
   "id": "2faf83b90aab0e0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.system(\"\"\"\n",
    "    docker compose down;\n",
    "    \"\"\")"
   ],
   "id": "9429fb15a90764ae",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
