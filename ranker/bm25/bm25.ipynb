{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T16:43:16.771622Z",
     "start_time": "2024-07-08T16:43:10.530997Z"
    }
   },
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import spacy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import spacy\n",
    "import nltk\n",
    "from transformers import BertTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:43:26.270342Z",
     "start_time": "2024-07-08T16:43:24.749484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Tokenizer functions for text processing\n",
    "def tokenizer(doc):\n",
    "    return doc.split()\n",
    "\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "    return [token.text for token in nlp(doc)]\n",
    "\n",
    "\n",
    "def nltk_lemmatizer(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "\n",
    "def bert_subword_tokenizer(tokens):\n",
    "    subwords = []\n",
    "    for token in tokens:\n",
    "        subwords.extend(bert_tokenizer.tokenize(token))\n",
    "    return subwords\n",
    "\n",
    "\n",
    "def combined_tokenizer(doc):\n",
    "    '''\n",
    "    Tokenizes the input document using a combination of spaCy, NLTK, and BERT tokenizers.\n",
    "    :param doc: str: Input document\n",
    "    :return: list: List of subword tokens\n",
    "    '''\n",
    "    spacy_tokens = spacy_tokenizer(doc)\n",
    "\n",
    "    # Step 2: Use NLTK for lemmatization\n",
    "    lemmatized_tokens = nltk_lemmatizer(spacy_tokens)\n",
    "\n",
    "    # Step 3: Use BERT for subword tokenization\n",
    "    bert_tokens = bert_subword_tokenizer(lemmatized_tokens)\n",
    "\n",
    "    return bert_tokens\n",
    "\n",
    "\n",
    "\n",
    "# Base Ranker class\n",
    "class Ranker(ABC):\n",
    "    @abstractmethod\n",
    "    def get_scores(self, query):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        pass\n",
    "\n",
    "    def search(self, query, corpus, n=5):\n",
    "        search1 = set(self.get_top_n(query, corpus, n))\n",
    "        search2 = set(self.get_top_n(query[0].split(\" \"), corpus, n))\n",
    "        return search2.intersection(search1)\n",
    "\n",
    "\n",
    "# BM25 and variants implementation\n",
    "class BM25:\n",
    "    def __init__(self, corpus, tokenizer=None):\n",
    "        self.corpus_size = 0\n",
    "        self.avgdl = 0\n",
    "        self.doc_freqs = []\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        if tokenizer:\n",
    "            corpus = self._tokenize_corpus(corpus)\n",
    "\n",
    "        nd = self._initialize(corpus)\n",
    "        self._calc_idf(nd)\n",
    "\n",
    "    def _initialize(self, corpus):\n",
    "        nd = {}\n",
    "        num_doc = 0\n",
    "        for document in corpus:\n",
    "            self.doc_len.append(len(document))\n",
    "            num_doc += len(document)\n",
    "\n",
    "            frequencies = {}\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.doc_freqs.append(frequencies)\n",
    "\n",
    "            for word, freq in frequencies.items():\n",
    "                try:\n",
    "                    nd[word] += 1\n",
    "                except KeyError:\n",
    "                    nd[word] = 1\n",
    "\n",
    "            self.corpus_size += 1\n",
    "\n",
    "        self.avgdl = num_doc / self.corpus_size\n",
    "        return nd\n",
    "\n",
    "    def _tokenize_corpus(self, corpus):\n",
    "        print('Tokenization successful.')\n",
    "        tokenized_corpus = [self.tokenizer(doc) for doc in corpus]\n",
    "        return tokenized_corpus\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "        scores = self.get_scores(query)\n",
    "        top_n = np.argsort(scores)[::-1][:n]\n",
    "        return [documents[i] for i in top_n]\n",
    "\n",
    "class BM25Okapi(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25, relevance_model=None):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        self.relevance_model = relevance_model\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        idf_sum = 0\n",
    "        negative_idfs = []\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = idf_sum / len(self.idf)\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
    "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        '''\n",
    "        Get the top n documents based on the BM25 score and the relevance score from the neural model.\n",
    "        :param query: list: List of query tokens\n",
    "        :param documents: list: List of documents in the corpus\n",
    "        :param n: int: Number of documents to return\n",
    "        :return: list: List of top n documents\n",
    "        :return: list: List of scores for the top n documents\n",
    "        '''\n",
    "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "        scores = self.get_scores(query)\n",
    "        \n",
    "        # Re-ranking using BERT embedding and cosine similarity\n",
    "        query_tokens = query\n",
    "        query_vec = bert_embedding(' '.join(query_tokens), bert_model, bert_tokenizer)\n",
    "    \n",
    "        combined_scores = []\n",
    "        for idx, score in enumerate(scores):\n",
    "            doc_tokens = documents[idx].split()\n",
    "            token_overlap = soft_token_overlap(query_tokens, doc_tokens)\n",
    "            doc_vec = bert_embedding(documents[idx], bert_model, bert_tokenizer)\n",
    "            similarity = cosine_sim(query_vec, doc_vec)\n",
    "            combined_score = score + token_overlap + similarity\n",
    "            combined_scores.append(combined_score)\n",
    "        \n",
    "        top_n_indices = np.argsort(combined_scores)[::-1][:n]\n",
    "        filtered_docs = []\n",
    "        relevance_scores = []\n",
    "        \n",
    "        # Applying the neural relevance filter\n",
    "        for i in top_n_indices:\n",
    "            features = torch.tensor([combined_scores[i]], dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                relevance_score = self.relevance_model(features).item()\n",
    "            if relevance_score >= 0.7:  # Threshold can be adjusted\n",
    "                filtered_docs.append(documents[i])\n",
    "                relevance_scores.append(relevance_score)\n",
    "            if len(filtered_docs) >= n:\n",
    "                break\n",
    "        \n",
    "        return filtered_docs, relevance_scores\n",
    "\n",
    "class BM25L(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=0.5):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = np.log(self.corpus_size + 1) - np.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            score += (self.idf.get(q) or 0) * (self.k1 + 1) * (ctd + self.delta) / \\\n",
    "                     (self.k1 + ctd + self.delta)\n",
    "        print(f\"Query: {query}, Scores: {score}\")\n",
    "        return score\n",
    "\n",
    "class BM25Plus(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=1):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size + 1) - math.log(freq)\n",
    "            self.idf[word] = idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
    "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
    "        print(f\"Query: {query}, Scores: {score}\")\n",
    "        return score\n",
    "\n",
    "class IDFDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features, idf = self.data[idx]\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(idf, dtype=torch.float32)\n",
    "    \n",
    "class RelevanceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features, label = self.data[idx]\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class IDFNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(IDFNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))  # Add bias as a parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x += self.bias\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "class NeuralBM25(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, idf_model=None, k1=1.5, b=0.75, delta=0.5):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        self.idf_model = idf_model\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        # No need to calculate IDF traditionally\n",
    "        pass\n",
    "\n",
    "    def get_idf(self, word_freq):\n",
    "        with torch.no_grad():\n",
    "            features = torch.tensor([word_freq], dtype=torch.float32)\n",
    "            idf = self.idf_model(features).item()\n",
    "        return idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            idf = self.get_idf(q_freq.mean())  # Using mean frequency for simplicity\n",
    "            score += idf * (self.k1 + 1) * (ctd + self.delta) / (self.k1 + ctd + self.delta)\n",
    "\n",
    "        print(f\"Query: {query}, Scores: {score}\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            idf = self.get_idf(q_freq.mean())  # Using mean frequency for simplicity\n",
    "            score += idf * (self.k1 + 1) * (ctd + self.delta) / (self.k1 + ctd + self.delta)\n",
    "        return score.tolist()\n",
    "    \n",
    "class RelevanceNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RelevanceNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# StatisticalRanker class to wrap the BM25 variants\n",
    "class StatisticalRanker(Ranker):\n",
    "    def __init__(self, corpus, ranker_type=\"bm25_okapi\", tokenizer=None, **kwargs):\n",
    "        self.corpus = corpus\n",
    "        self.tokenizer = tokenizer or tokenizer\n",
    "        self.ranker = self._initialize_ranker(ranker_type, **kwargs)\n",
    "        self.ranker_name = ranker_type\n",
    "\n",
    "    def _initialize_ranker(self, ranker_type, **kwargs):\n",
    "        if ranker_type != \"neural\" and kwargs.get(\"idf_model\"):\n",
    "            raise ValueError(\"IDF model not required for statistical rankers. Please remove the 'idf_model' argument.\")\n",
    "        if ranker_type == \"bm25_okapi\":\n",
    "            return BM25Okapi(self.corpus, self.tokenizer, **kwargs)\n",
    "        elif ranker_type == \"bm25_plus\":\n",
    "            return BM25Plus(self.corpus, self.tokenizer, **kwargs)\n",
    "        elif ranker_type == \"bm25_l\":\n",
    "            return BM25L(self.corpus, self.tokenizer, **kwargs)\n",
    "        elif ranker_type == \"neural\":\n",
    "            idf_model = kwargs.get(\"idf_model\")\n",
    "            return NeuralBM25(corpus=self.corpus, tokenizer=self.tokenizer, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranker type: {ranker_type}. Valid options are 'bm25_okapi', 'bm25_plus', 'bm25_l', 'neural'.\")\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        return self.ranker.get_scores(query)\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        return self.ranker.get_top_n(query, documents, n)\n",
    "\n",
    "\n",
    "# RankerFactory to create rankers\n",
    "class RankerFactory:\n",
    "    @staticmethod\n",
    "    def create_ranker(ranker_type, corpus=None, tokenizer=None, **kwargs):\n",
    "        if ranker_type in ['bm25_okapi', 'bm25_plus', 'bm25_l']:\n",
    "            return StatisticalRanker(corpus, ranker_type=ranker_type, tokenizer=tokenizer, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranker type: {ranker_type}\")\n",
    "\n",
    "\n",
    "\n",
    "# Training data preparation (example)\n",
    "def prepare_training_data(corpus, idf_values):\n",
    "    training_data = []\n",
    "    for word, idf in idf_values.items():\n",
    "        freq = sum([1 for doc in corpus if word in doc])\n",
    "        features = [freq]  # Add more features if necessary\n",
    "        training_data.append((features, idf))\n",
    "    return training_data\n",
    "\n",
    "# Example training process\n",
    "def train_idf_model(training_data, epochs=100, lr=0.001):\n",
    "    dataset = IDFDataset(training_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    model = IDFNet(input_size=len(training_data[0][0]))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for features, idf in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.squeeze(), idf)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_relevance_model(training_data, epochs=100, lr=0.001):\n",
    "    dataset = RelevanceDataset(training_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    model = RelevanceNet(input_size=len(training_data[0][0]))\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for features, label in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_idf(tokenized_corpus):\n",
    "    num_docs = len(tokenized_corpus)\n",
    "    doc_freqs = defaultdict(int)\n",
    "\n",
    "    for doc in tokenized_corpus:\n",
    "        unique_words = set(doc)\n",
    "        for word in unique_words:\n",
    "            doc_freqs[word] += 1\n",
    "\n",
    "    idf_scores = {word: math.log(num_docs / (freq + 1)) + 1 for word, freq in doc_freqs.items()}\n",
    "    return idf_scores\n",
    "\n",
    "\n",
    "def generate_neural_idf_scores(corpus, idf_model, tokenizer):\n",
    "    tokenized_corpus = [tokenizer(doc) for doc in corpus]\n",
    "    word_freqs = defaultdict(int)\n",
    "    for doc in tokenized_corpus:\n",
    "        for word in doc:\n",
    "            word_freqs[word] += 1\n",
    "\n",
    "    neural_idf_scores = {}\n",
    "    for word, freq in word_freqs.items():\n",
    "        features = torch.tensor([[freq]], dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            idf = idf_model(features).item()\n",
    "        neural_idf_scores[word] = idf\n",
    "\n",
    "    return neural_idf_scores\n",
    "\n",
    "\n",
    "def label_corpus_with_idf(corpus_df, neural_idf_scores):\n",
    "    tokenized_corpus = [tokenizer(doc) for doc in corpus_df['text']]\n",
    "    idf_labels = []\n",
    "    for doc in tokenized_corpus:\n",
    "        idf_score = sum(neural_idf_scores[word] for word in doc) / len(doc)  # Average IDF score\n",
    "        idf_labels.append(idf_score)\n",
    "    corpus_df['idf_score'] = idf_labels\n",
    "    \n",
    "    \n",
    "\n",
    "def soft_token_overlap(query_tokens, doc_tokens):\n",
    "    query_set = set(query_tokens)\n",
    "    doc_set = set(doc_tokens)\n",
    "    intersection = query_set.intersection(doc_set)\n",
    "    union = query_set.union(doc_set)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def bert_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "def cosine_sim(query_vec, doc_vec):\n",
    "    return cosine_similarity(query_vec, doc_vec)[0][0]"
   ],
   "id": "7a9f94563640b560",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:43:32.614220Z",
     "start_time": "2024-07-08T16:43:32.607843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_df = pd.read_csv('../../dummyindex.csv', delimiter=',')\n",
    "corpus = corpus_df['text'].tolist()"
   ],
   "id": "8191095bab457417",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:43:33.827385Z",
     "start_time": "2024-07-08T16:43:33.819813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTTokenizerWrapper:\n",
    "    def __init__(self, pretrained_model='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "        self.model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "    def tokenize(self, doc):\n",
    "        inputs = self.tokenizer(doc, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "class BERTTokenizerWrapper:\n",
    "    def __init__(self, pretrained_model='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "    def tokenize(self, doc):\n",
    "        tokens = self.tokenizer.tokenize(doc)\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "def soft_token_overlap(query_tokens, doc_tokens):\n",
    "    query_set = set(query_tokens)\n",
    "    doc_set = set(doc_tokens)\n",
    "    intersection = query_set.intersection(doc_set)\n",
    "    union = query_set.union(doc_set)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def bert_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "def cosine_sim(query_vec, doc_vec):\n",
    "    return cosine_similarity(query_vec, doc_vec)[0][0]"
   ],
   "id": "d5473d8652e77ff3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:43:44.711548Z",
     "start_time": "2024-07-08T16:43:39.954035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def monte_carlo_tuples(n=1000, threshold=0.5, false_negative_rate=0.1, false_positive_rate=0.1):\n",
    "    \"\"\"\n",
    "    Generate tuples using the Monte Carlo method with noise to introduce false negatives and false positives.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): Number of tuples to generate.\n",
    "    threshold (float): Threshold to determine the label. If the score is above the threshold, the label is 1; otherwise, it's 0.\n",
    "    false_negative_rate (float): Probability of labeling a high score as 0.\n",
    "    false_positive_rate (float): Probability of labeling a low score as 1.\n",
    "\n",
    "    Returns:\n",
    "    list: List of tuples where each tuple contains a list of scores and a label.\n",
    "    \"\"\"\n",
    "    tuples = []\n",
    "    for _ in range(n):\n",
    "        score = random.uniform(0, 1)  # Generate a random score between 0 and 1\n",
    "        if score > threshold:\n",
    "            label = 0 if random.random() < false_negative_rate else 1\n",
    "        else:\n",
    "            label = 1 if random.random() < false_positive_rate else 0\n",
    "        tuples.append(([score], label))\n",
    "    return tuples\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    corpus_df = pd.read_csv('../../dummyindex.csv', delimiter=',')\n",
    "    corpus = corpus_df['text'].tolist()\n",
    "\n",
    "    # Example training data for relevance model\n",
    "    # make monte carlo data set 0.7 threshold\n",
    "    relevance_training_data = monte_carlo_tuples(n=1000, threshold=0.5, false_negative_rate=0.1, false_positive_rate=0.01)\n",
    "\n",
    "    relevance_model = train_relevance_model(relevance_training_data)\n",
    "\n",
    "    # Test BM25Okapi with combined tokenization and re-ranking with neural filter\n",
    "    ranker = RankerFactory.create_ranker('bm25_okapi', corpus=corpus, tokenizer=combined_tokenizer, relevance_model=relevance_model)\n",
    "    query = combined_tokenizer('Statue of Liberty')\n",
    "    top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "    \n",
    "    print(\"Top Documents:\")\n",
    "    for doc in top_n_documents:\n",
    "        print(doc)\n"
   ],
   "id": "9c9ed541b203b568",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Loss: 0.5305\n",
      "Epoch [10/100], Loss: 0.0606\n",
      "Epoch [20/100], Loss: 0.3761\n",
      "Epoch [30/100], Loss: 0.1355\n",
      "Epoch [40/100], Loss: 0.5281\n",
      "Epoch [50/100], Loss: 0.0867\n",
      "Epoch [60/100], Loss: 0.2405\n",
      "Epoch [70/100], Loss: 0.0805\n",
      "Epoch [80/100], Loss: 0.0749\n",
      "Epoch [90/100], Loss: 0.7968\n",
      "Tokenization successful.\n",
      "Top Documents:\n",
      "['Bejing is the capital of China or better said the Peoples Republic of China. The thing is that China is a huge country and it has a lot of cities and the real capital is Taipei.', 'Berlin is the capital and largest city of Germany by both area and population.', \"Taiwan is a country in East Asia. Neighbouring countries include the People's Republic of China (PRC) to the northwest, Japan to the northeast, and the Philippines to the south. The capital of Taiwan is Taipei. Approximately 23.5 million people live in Taiwan. Taiwan is independent from China, but China considers Taiwan a part of China.\", 'Rome is the capital of Italy and a special comune (named Comune di Roma Capitale).', 'The official home of Jaguar USA. Explore our luxury sedans, SUVs and sports cars.']\n",
      "[0.9557557702064514, 0.9720126390457153, 0.9007936716079712, 0.9086739420890808, 0.9177352786064148]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:44:07.684938Z",
     "start_time": "2024-07-08T16:44:06.210772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test BM25Okapi with combined tokenization and re-ranking\n",
    "ranker = RankerFactory.create_ranker('bm25_okapi', corpus=corpus, tokenizer=combined_tokenizer)\n",
    "query = combined_tokenizer('Statue of Liberty')\n",
    "top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "\n",
    "print(\"Top Documents:\")\n",
    "for doc in top_n_documents:\n",
    "    print(doc)\n",
    "\n",
    "# Test BM25L with spaCy tokenization\n",
    "ranker = RankerFactory.create_ranker('bm25_l', corpus=corpus, tokenizer=spacy_tokenizer)\n",
    "query = spacy_tokenizer('Statue of Liberty')\n",
    "top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "    "
   ],
   "id": "123f4e1593861e06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization successful.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m ranker \u001B[38;5;241m=\u001B[39m RankerFactory\u001B[38;5;241m.\u001B[39mcreate_ranker(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbm25_okapi\u001B[39m\u001B[38;5;124m'\u001B[39m, corpus\u001B[38;5;241m=\u001B[39mcorpus, tokenizer\u001B[38;5;241m=\u001B[39mcombined_tokenizer)\n\u001B[1;32m      3\u001B[0m query \u001B[38;5;241m=\u001B[39m combined_tokenizer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStatue of Liberty\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m top_n_documents \u001B[38;5;241m=\u001B[39m \u001B[43mranker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_top_n\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTop Documents:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m top_n_documents:\n",
      "Cell \u001B[0;32mIn[2], line 373\u001B[0m, in \u001B[0;36mStatisticalRanker.get_top_n\u001B[0;34m(self, query, documents, n)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_top_n\u001B[39m(\u001B[38;5;28mself\u001B[39m, query, documents, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m--> 373\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mranker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_top_n\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[2], line 187\u001B[0m, in \u001B[0;36mBM25Okapi.get_top_n\u001B[0;34m(self, query, documents, n)\u001B[0m\n\u001B[1;32m    185\u001B[0m features \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([combined_scores[i]], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 187\u001B[0m     relevance_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelevance_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m relevance_score \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.7\u001B[39m:  \u001B[38;5;66;03m# Threshold can be adjusted\u001B[39;00m\n\u001B[1;32m    189\u001B[0m     filtered_docs\u001B[38;5;241m.\u001B[39mappend(documents[i])\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1ca9739baeb39070",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
