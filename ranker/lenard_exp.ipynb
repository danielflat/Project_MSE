{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T16:50:28.137389Z",
     "start_time": "2024-06-27T16:50:23.776900Z"
    }
   },
   "source": "! pip install datasets torch pandas transformers lightgbm scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (2.20.0)\r\n",
      "Requirement already satisfied: torch in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: pandas in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: transformers in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (4.41.2)\r\n",
      "Requirement already satisfied: lightgbm in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (4.4.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (1.5.0)\r\n",
      "Requirement already satisfied: filelock in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (3.15.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (16.1.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (4.66.4)\r\n",
      "Requirement already satisfied: xxhash in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (3.9.5)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (0.23.4)\r\n",
      "Requirement already satisfied: packaging in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from pandas) (2.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: scipy in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from lightgbm) (1.14.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/lenardrommel/miniconda3/envs/Project_MSE/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:44:34.696787Z",
     "start_time": "2024-06-28T13:44:26.986738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import datasets as ds\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "id": "ee2b1698853c1a99",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:54:57.210893Z",
     "start_time": "2024-06-27T16:54:53.810579Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = ds.load_dataset(\"microsoft/ms_marco\", \"v1.1\") # change this to v2.1 for the full dataset",
   "id": "be0d6bef39bfa08f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:55:15.300054Z",
     "start_time": "2024-06-27T16:55:15.296948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show example of the dataset\n",
    "len(dataset['train'])"
   ],
   "id": "d33781a8cfbeba8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82326"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:55:35.328098Z",
     "start_time": "2024-06-27T16:55:34.580034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract queries, passages, and relevance labels\n",
    "def prepare_data(dataset_split, num_samples=None):\n",
    "    queries = []\n",
    "    passages = []\n",
    "    labels = []\n",
    "    query_ids = []\n",
    "    \n",
    "    if num_samples is None:\n",
    "        num_samples = len(dataset_split)\n",
    "\n",
    "    for i in range(min(num_samples, len(dataset_split))):  # Ensure we only use a subset of the data\n",
    "        example = dataset_split[i]\n",
    "        query_id = example['query_id']\n",
    "        query = example['query']\n",
    "        passage_texts = example['passages']['passage_text']\n",
    "        is_selecteds = example['passages']['is_selected']\n",
    "        \n",
    "        # Ensure we have lists of the same length\n",
    "        if len(passage_texts) != len(is_selecteds):\n",
    "            continue\n",
    "        \n",
    "        for passage_text, is_selected in zip(passage_texts, is_selecteds):\n",
    "            queries.append(query)\n",
    "            passages.append(passage_text)\n",
    "            labels.append(is_selected)\n",
    "            query_ids.append(query_id)\n",
    "\n",
    "    return pd.DataFrame({'query_id': query_ids, 'query': queries, 'passage': passages, 'label': labels})\n",
    "\n",
    "# Prepare a subset of the train and validation data\n",
    "train_df = prepare_data(dataset['train'], num_samples=10000)\n",
    "valid_df = prepare_data(dataset['validation'], num_samples=1000)"
   ],
   "id": "68e726032a950a3a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:02:17.130520Z",
     "start_time": "2024-06-27T17:02:14.022728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "all_text = train_df['query'] + \" \" + train_df['passage']\n",
    "vectorizer.fit(all_text)"
   ],
   "id": "f648fb2aee79e7d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=5000)"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=5000)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:55:53.293950Z",
     "start_time": "2024-06-27T16:55:50.096470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_queries = vectorizer.transform(train_df['query'])\n",
    "X_train_passages = vectorizer.transform(train_df['passage'])\n",
    "X_train = np.hstack([X_train_queries.toarray(), X_train_passages.toarray()])"
   ],
   "id": "7a9375812d8dd3a6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:55:54.286141Z",
     "start_time": "2024-06-27T16:55:53.950159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_valid_queries = vectorizer.transform(valid_df['query'])\n",
    "X_valid_passages = vectorizer.transform(valid_df['passage'])\n",
    "X_valid = np.hstack([X_valid_queries.toarray(), X_valid_passages.toarray()])"
   ],
   "id": "c8d470af7f443882",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:55:54.921069Z",
     "start_time": "2024-06-27T16:55:54.915881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = train_df['label'].values\n",
    "y_valid = valid_df['label'].values\n",
    "\n",
    "group_train = train_df.groupby('query_id').size().values\n",
    "group_valid = valid_df.groupby('query_id').size().values"
   ],
   "id": "22662f60b2e8d07d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:16:04.652013Z",
     "start_time": "2024-06-27T17:16:04.645714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the LambdaMART model deterministically\n",
    "train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid, group=group_valid, reference=train_data)"
   ],
   "id": "ec92b05c1ec4c6de",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:16:23.346502Z",
     "start_time": "2024-06-27T17:16:21.953159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [10],\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'max_bin': 255,\n",
    "    'bagging_fraction': 0.8,       # Randomly select 80% of the data for each iteration\n",
    "    'bagging_freq': 1,             # Perform bagging every iteration\n",
    "    'feature_fraction': 0.8,       # Randomly select 80% of features for each split\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "# Callbacks for verbosity and early stopping\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=10),\n",
    "    lgb.log_evaluation(period=1)\n",
    "]\n",
    "\n",
    "# Train the model with fewer rounds for quick testing\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  valid_sets=[train_data, valid_data],\n",
    "                  num_boost_round=1000,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "valid_df['pred'] = y_pred\n",
    "grouped_valid = valid_df.groupby('query_id')\n",
    "\n",
    "ndcg_scores = []\n",
    "for name, group in grouped_valid:\n",
    "    true_relevance = group['label'].values\n",
    "    scores = group['pred'].values\n",
    "    ndcg_scores.append(ndcg_score([true_relevance], [scores], k=10))\n",
    "\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "print(f\"Average NDCG: {average_ndcg}\")"
   ],
   "id": "940f1e58fef980f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 260596\n",
      "[LightGBM] [Info] Number of data points in the train set: 82193, number of used features: 1779\n",
      "[1]\ttraining's ndcg@10: 0.558436\tvalid_1's ndcg@10: 0.554776\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's ndcg@10: 0.574545\tvalid_1's ndcg@10: 0.554676\n",
      "[3]\ttraining's ndcg@10: 0.585938\tvalid_1's ndcg@10: 0.552979\n",
      "[4]\ttraining's ndcg@10: 0.592649\tvalid_1's ndcg@10: 0.54995\n",
      "[5]\ttraining's ndcg@10: 0.600894\tvalid_1's ndcg@10: 0.551848\n",
      "[6]\ttraining's ndcg@10: 0.607162\tvalid_1's ndcg@10: 0.557258\n",
      "[7]\ttraining's ndcg@10: 0.614062\tvalid_1's ndcg@10: 0.552298\n",
      "[8]\ttraining's ndcg@10: 0.619025\tvalid_1's ndcg@10: 0.553664\n",
      "[9]\ttraining's ndcg@10: 0.623684\tvalid_1's ndcg@10: 0.554468\n",
      "[10]\ttraining's ndcg@10: 0.628659\tvalid_1's ndcg@10: 0.553983\n",
      "[11]\ttraining's ndcg@10: 0.634616\tvalid_1's ndcg@10: 0.554248\n",
      "[12]\ttraining's ndcg@10: 0.638176\tvalid_1's ndcg@10: 0.559695\n",
      "[13]\ttraining's ndcg@10: 0.641259\tvalid_1's ndcg@10: 0.562732\n",
      "[14]\ttraining's ndcg@10: 0.645288\tvalid_1's ndcg@10: 0.561054\n",
      "[15]\ttraining's ndcg@10: 0.648712\tvalid_1's ndcg@10: 0.559349\n",
      "[16]\ttraining's ndcg@10: 0.653202\tvalid_1's ndcg@10: 0.560467\n",
      "[17]\ttraining's ndcg@10: 0.657045\tvalid_1's ndcg@10: 0.56227\n",
      "[18]\ttraining's ndcg@10: 0.660937\tvalid_1's ndcg@10: 0.562732\n",
      "[19]\ttraining's ndcg@10: 0.663372\tvalid_1's ndcg@10: 0.564903\n",
      "[20]\ttraining's ndcg@10: 0.666539\tvalid_1's ndcg@10: 0.563154\n",
      "[21]\ttraining's ndcg@10: 0.669558\tvalid_1's ndcg@10: 0.560705\n",
      "[22]\ttraining's ndcg@10: 0.672384\tvalid_1's ndcg@10: 0.565005\n",
      "[23]\ttraining's ndcg@10: 0.676352\tvalid_1's ndcg@10: 0.565418\n",
      "[24]\ttraining's ndcg@10: 0.679143\tvalid_1's ndcg@10: 0.567459\n",
      "[25]\ttraining's ndcg@10: 0.681175\tvalid_1's ndcg@10: 0.566753\n",
      "[26]\ttraining's ndcg@10: 0.682588\tvalid_1's ndcg@10: 0.56298\n",
      "[27]\ttraining's ndcg@10: 0.68564\tvalid_1's ndcg@10: 0.562107\n",
      "[28]\ttraining's ndcg@10: 0.68982\tvalid_1's ndcg@10: 0.561998\n",
      "[29]\ttraining's ndcg@10: 0.692197\tvalid_1's ndcg@10: 0.563941\n",
      "[30]\ttraining's ndcg@10: 0.694706\tvalid_1's ndcg@10: 0.56239\n",
      "[31]\ttraining's ndcg@10: 0.696972\tvalid_1's ndcg@10: 0.562384\n",
      "[32]\ttraining's ndcg@10: 0.700927\tvalid_1's ndcg@10: 0.55808\n",
      "[33]\ttraining's ndcg@10: 0.703011\tvalid_1's ndcg@10: 0.559931\n",
      "[34]\ttraining's ndcg@10: 0.705201\tvalid_1's ndcg@10: 0.560245\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's ndcg@10: 0.679143\tvalid_1's ndcg@10: 0.567459\n",
      "Average NDCG: 0.5346959275303146\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:16:24.642213Z",
     "start_time": "2024-06-27T17:16:24.625085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "model.save_model('lambdamart_model.txt')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ],
   "id": "c552f7de549034dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:16:25.328732Z",
     "start_time": "2024-06-27T17:16:25.311747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model and the vectorizer\n",
    "model = lgb.Booster(model_file='lambdamart_model.txt')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "def rank_documents(query, documents):\n",
    "    # Transform the query and documents using the vectorizer\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    doc_vecs = vectorizer.transform(documents)\n",
    "\n",
    "    # Combine the query and document vectors\n",
    "    combined_vecs = np.hstack([np.tile(query_vec.toarray(), (len(documents), 1)), doc_vecs.toarray()])\n",
    "\n",
    "    # Predict scores using the model\n",
    "    scores = model.predict(combined_vecs)\n",
    "\n",
    "    # Rank documents by score\n",
    "    ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in ranked_docs], scores\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the capital of Italy?\"\n",
    "documents = [\n",
    "    \"London is the capital of the United Kingdom.\",\n",
    "    \"Berlin is the capital of Germany.\",\n",
    "    \"Pjongyang is the capital of North Korea.\",\n",
    "    \"Tokyo is the capital of Japan.\",\n",
    "    \"Beijing is the capital of China.\",\n",
    "    \"Paris is the capital of France.\",\n",
    "    \"Madrid is the capital of Spain.\",\n",
    "    \"Rome is the capital of Italy.\"\n",
    "]\n",
    "documents = np.random.choice(documents, len(documents), replace=False)\n",
    "ranked_documents, scores = rank_documents(query, documents)\n",
    "print(query)\n",
    "print(ranked_documents[0])"
   ],
   "id": "bd4741269a74d3bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of Italy?\n",
      "Paris is the capital of France.\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:29:59.927924Z",
     "start_time": "2024-06-27T17:29:33.756533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the MS MARCO v1.1 dataset\n",
    "dataset = ds.load_dataset(\"ms_marco\", \"v1.1\")\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(dataset_split, num_samples=None):\n",
    "    queries = []\n",
    "    passages = []\n",
    "    labels = []\n",
    "    query_ids = []\n",
    "\n",
    "    if num_samples is None:\n",
    "        num_samples = len(dataset_split)\n",
    "\n",
    "    for i in range(min(num_samples, len(dataset_split))):\n",
    "        example = dataset_split[i]\n",
    "        query_id = example['query_id']\n",
    "        query = example['query']\n",
    "        passage_texts = example['passages']['passage_text']\n",
    "        is_selecteds = example['passages']['is_selected']\n",
    "        \n",
    "        if len(passage_texts) != len(is_selecteds):\n",
    "            continue\n",
    "        \n",
    "        for passage_text, is_selected in zip(passage_texts, is_selecteds):\n",
    "            queries.append(query)\n",
    "            passages.append(passage_text)\n",
    "            labels.append(is_selected)\n",
    "            query_ids.append(query_id)\n",
    "\n",
    "    return pd.DataFrame({'query_id': query_ids, 'query': queries, 'passage': passages, 'label': labels})\n",
    "\n",
    "# Prepare the train and validation data\n",
    "train_df = prepare_data(dataset['train'], num_samples=10000)\n",
    "valid_df = prepare_data(dataset['validation'], num_samples=1000)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(train_df.head())\n",
    "print(\"Validation data:\")\n",
    "print(valid_df.head())"
   ],
   "id": "d552cd1399ef1b48",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.48k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cee13c02d721499ba7cfb2b378113ad0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e17cdbc41f94d25b258200689737498"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/175M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cad4ded0cee241478911079b1dd91041"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "605a9941f4ac4a79b77590eaf79d9842"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/10047 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e907707076c4a9fa9b5c9add74086a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/82326 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10acb0b6c10846f0bb1eff9d820db72b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/9650 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bc6b3978c934fa0afe58928f3aaf1c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "   query_id        query                                            passage  \\\n",
      "0     19699  what is rba  Since 2007, the RBA's outstanding reputation h...   \n",
      "1     19699  what is rba  The Reserve Bank of Australia (RBA) came into ...   \n",
      "2     19699  what is rba  RBA Recognized with the 2014 Microsoft US Regi...   \n",
      "3     19699  what is rba  The inner workings of a rebuildable atomizer a...   \n",
      "4     19699  what is rba  Results-Based Accountability® (also known as R...   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "Validation data:\n",
      "   query_id                          query  \\\n",
      "0      9652  walgreens store sales average   \n",
      "1      9652  walgreens store sales average   \n",
      "2      9652  walgreens store sales average   \n",
      "3      9652  walgreens store sales average   \n",
      "4      9652  walgreens store sales average   \n",
      "\n",
      "                                             passage  label  \n",
      "0  The average Walgreens salary ranges from appro...      1  \n",
      "1  The average revenue in 2011 of a Starbuck Stor...      0  \n",
      "2  In fiscal 2014, Walgreens opened a total of 18...      0  \n",
      "3  th store in 1984, reaching $4 billion in sales...      0  \n",
      "4  The number of Walgreen stores has risen from 5...      0  \n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-27T17:33:00.052556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=100000)\n",
    "all_text = train_df['query'] + \" \" + train_df['passage']\n",
    "vectorizer.fit(all_text)\n",
    "\n",
    "X_train_queries = vectorizer.transform(train_df['query'])\n",
    "X_train_passages = vectorizer.transform(train_df['passage'])\n",
    "X_train = np.hstack([X_train_queries.toarray(), X_train_passages.toarray()])\n",
    "\n",
    "X_valid_queries = vectorizer.transform(valid_df['query'])\n",
    "X_valid_passages = vectorizer.transform(valid_df['passage'])\n",
    "X_valid = np.hstack([X_valid_queries.toarray(), X_valid_passages.toarray()])\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape)"
   ],
   "id": "eb1c3b0399d22a83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:30:43.422989Z",
     "start_time": "2024-06-27T17:30:27.558316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure labels and groups are correct\n",
    "y_train = train_df['label'].values\n",
    "y_valid = valid_df['label'].values\n",
    "\n",
    "group_train = train_df.groupby('query_id').size().values\n",
    "group_valid = valid_df.groupby('query_id').size().values\n",
    "\n",
    "print(\"y_train distribution:\", np.bincount(y_train))\n",
    "print(\"y_valid distribution:\", np.bincount(y_valid))\n",
    "\n",
    "# Train the LambdaMART model deterministically\n",
    "train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid, group=group_valid, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [10],\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'max_bin': 255,\n",
    "    'bagging_fraction': 0.8,       # Randomly select 80% of the data for each iteration\n",
    "    'bagging_freq': 1,             # Perform bagging every iteration\n",
    "    'feature_fraction': 0.8,       # Randomly select 80% of features for each split\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=10),\n",
    "    lgb.log_evaluation(period=1)\n",
    "]\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  valid_sets=[train_data, valid_data],\n",
    "                  num_boost_round=1000,\n",
    "                  callbacks=callbacks)"
   ],
   "id": "c92c8b3886ce22b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train distribution: [71371 10822]\n",
      "y_valid distribution: [7171 1072]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.669625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 648318\n",
      "[LightGBM] [Info] Number of data points in the train set: 82193, number of used features: 12202\n",
      "[1]\ttraining's ndcg@10: 0.558365\tvalid_1's ndcg@10: 0.530948\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's ndcg@10: 0.573781\tvalid_1's ndcg@10: 0.539738\n",
      "[3]\ttraining's ndcg@10: 0.585284\tvalid_1's ndcg@10: 0.545611\n",
      "[4]\ttraining's ndcg@10: 0.595134\tvalid_1's ndcg@10: 0.557664\n",
      "[5]\ttraining's ndcg@10: 0.602003\tvalid_1's ndcg@10: 0.558415\n",
      "[6]\ttraining's ndcg@10: 0.608862\tvalid_1's ndcg@10: 0.559935\n",
      "[7]\ttraining's ndcg@10: 0.61376\tvalid_1's ndcg@10: 0.559038\n",
      "[8]\ttraining's ndcg@10: 0.618784\tvalid_1's ndcg@10: 0.562971\n",
      "[9]\ttraining's ndcg@10: 0.622758\tvalid_1's ndcg@10: 0.564071\n",
      "[10]\ttraining's ndcg@10: 0.627717\tvalid_1's ndcg@10: 0.561344\n",
      "[11]\ttraining's ndcg@10: 0.632585\tvalid_1's ndcg@10: 0.55768\n",
      "[12]\ttraining's ndcg@10: 0.637024\tvalid_1's ndcg@10: 0.553053\n",
      "[13]\ttraining's ndcg@10: 0.643483\tvalid_1's ndcg@10: 0.555408\n",
      "[14]\ttraining's ndcg@10: 0.6475\tvalid_1's ndcg@10: 0.553368\n",
      "[15]\ttraining's ndcg@10: 0.652074\tvalid_1's ndcg@10: 0.55535\n",
      "[16]\ttraining's ndcg@10: 0.65555\tvalid_1's ndcg@10: 0.553103\n",
      "[17]\ttraining's ndcg@10: 0.658873\tvalid_1's ndcg@10: 0.555542\n",
      "[18]\ttraining's ndcg@10: 0.662651\tvalid_1's ndcg@10: 0.55452\n",
      "[19]\ttraining's ndcg@10: 0.666629\tvalid_1's ndcg@10: 0.554534\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's ndcg@10: 0.622758\tvalid_1's ndcg@10: 0.564071\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:30:47.670933Z",
     "start_time": "2024-06-27T17:30:47.386127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "valid_df['pred'] = y_pred\n",
    "grouped_valid = valid_df.groupby('query_id')\n",
    "\n",
    "ndcg_scores = []\n",
    "for name, group in grouped_valid:\n",
    "    true_relevance = group['label'].values\n",
    "    scores = group['pred'].values\n",
    "    ndcg_scores.append(ndcg_score([true_relevance], [scores], k=10))\n",
    "\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "print(f\"Average NDCG: {average_ndcg}\")"
   ],
   "id": "e46d7289774ac98f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG: 0.5315783471318544\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:30:53.632636Z",
     "start_time": "2024-06-27T17:30:53.528316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "model.save_model('lambdamart_model.txt')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ],
   "id": "df688904ef3bbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:30:59.057287Z",
     "start_time": "2024-06-27T17:30:58.985943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Load the model and the vectorizer\n",
    "model = lgb.Booster(model_file='lambdamart_model.txt')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')"
   ],
   "id": "bf03e2a0f70b5bbf",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:31:11.899020Z",
     "start_time": "2024-06-27T17:31:11.892684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rank_documents(query, documents):\n",
    "    # Transform the query and documents using the vectorizer\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    doc_vecs = vectorizer.transform(documents)\n",
    "\n",
    "    # Combine the query and document vectors\n",
    "    combined_vecs = np.hstack([np.tile(query_vec.toarray(), (len(documents), 1)), doc_vecs.toarray()])\n",
    "\n",
    "    # Predict scores using the model\n",
    "    scores = model.predict(combined_vecs)\n",
    "\n",
    "    # Rank documents by score\n",
    "    ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in ranked_docs], scores\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the capital of Italy?\"\n",
    "documents = [\n",
    "    \"London is the capital of the United Kingdom.\",\n",
    "    \"Berlin is the capital of Germany.\",\n",
    "    \"Pjongyang is the capital of North Korea.\",\n",
    "    \"Tokyo is the capital of Japan.\",\n",
    "    \"Beijing is the capital of China.\",\n",
    "    \"Paris is the capital of France.\",\n",
    "    \"Madrid is the capital of Spain.\",\n",
    "    \"Rome is the capital of Italy.\"\n",
    "]\n",
    "documents = np.random.choice(documents, len(documents), replace=False)\n",
    "ranked_documents, scores = rank_documents(query, documents)\n",
    "print(\"Query:\", query)\n",
    "print(\"Ranked Documents:\", ranked_documents)\n",
    "print(\"Scores:\", scores)"
   ],
   "id": "2cac51499c2d65b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the capital of Italy?\n",
      "Ranked Documents: [np.str_('Tokyo is the capital of Japan.'), np.str_('Pjongyang is the capital of North Korea.'), np.str_('Paris is the capital of France.'), np.str_('Beijing is the capital of China.'), np.str_('London is the capital of the United Kingdom.'), np.str_('Rome is the capital of Italy.'), np.str_('Berlin is the capital of Germany.'), np.str_('Madrid is the capital of Spain.')]\n",
      "Scores: [ 0.01879778  0.01879778  0.01879778  0.01879778  0.01879778  0.01879778\n",
      "  0.01879778 -0.06765718]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:35:38.304793Z",
     "start_time": "2024-06-28T13:34:42.889170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BatchEncoding, PreTrainedTokenizerFast\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "def encode(tokenizer: PreTrainedTokenizerFast,\n",
    "           query: str, passage: str, title: str = '-') -> BatchEncoding:\n",
    "    return tokenizer(query,\n",
    "                     text_pair='{}: {}'.format(title, passage),\n",
    "                     max_length=192,\n",
    "                     padding=True,\n",
    "                     truncation=True,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/simlm-msmarco-reranker')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('intfloat/simlm-msmarco-reranker')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_dict = encode(tokenizer, 'how long is super bowl game', 'The Super Bowl is typically four hours long. The game itself takes about three and a half hours, with a 30 minute halftime show built in.')\n",
    "    outputs: SequenceClassifierOutput = model(**batch_dict, return_dict=True)\n",
    "    print(outputs.logits[0])\n",
    "\n",
    "    batch_dict = encode(tokenizer, 'how long is super bowl game', 'The cost of a Super Bowl commercial runs about $5 million for 30 seconds of airtime. But the benefits that the spot can bring to a brand can help to justify the cost.')\n",
    "    outputs: SequenceClassifierOutput = model(**batch_dict, return_dict=True)\n",
    "    print(outputs.logits[0])"
   ],
   "id": "5d111c52f968b3d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bca88b7e302e4a728c32d8a991279c00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7e3566c3df0483e84ccd42778cf5b32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cad8633e66064ca3a2ff140b510baa4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce0c029ce15044818fe6e938c4399aee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/886 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d78014b4a7eb413f8934f839ce4f74ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1aea83d426343b9a20e45c12d641385"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6007])\n",
      "tensor([-4.2239])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T14:30:46.861802Z",
     "start_time": "2024-06-28T14:30:45.633085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rank_documents(query, documents):\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for doc in documents:\n",
    "            batch_dict = encode(tokenizer, query, doc)\n",
    "            outputs: SequenceClassifierOutput = model(**batch_dict, return_dict=True)\n",
    "            score = outputs.logits[0].item()\n",
    "            scores.append(score)\n",
    "\n",
    "    ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in ranked_docs], scores\n",
    "\n",
    "# Example usage\n",
    "query = \"Jaguar cars\"\n",
    "documents = [\n",
    "    \"The official home of Jaguar USA. Explore our luxury sedans, SUVs and sports cars.\",\n",
    "    \"Discover the different language sites we have to make browsing our vehicle range's easier.\",\n",
    "    \"Jaguar is the luxury vehicle brand of Jaguar Land Rover, a British multinational car manufacturer with its headquarters in Whitley, Coventry, England.\",\n",
    "    \"Jaguar has been making luxurious sedans and athletic sports cars for decades, but more recently it has added crossovers and SUVs that continue to perpetuate these trademark attributes.\",\n",
    "    \"This storied British luxury and sports car brand is famous for striking looks, agility, ride comfort, and powerful engines.\",\n",
    "    \"Used Jaguar for Sale. Search new and used cars, research vehicle models, and compare cars.\",\n",
    "    \"Jaguar is a premium automaker whose historic resonance is matched by few others.\",\n",
    "    \"What new Jaguar should you buy? With rankings, reviews, and specs of Jaguar vehicles, we are here to help you find your perfect car.\",\n",
    "    \"Some Jaguar models have supercharged V8 engines and sharp handling, from sports cars like the F-Type to sporty SUVs like the F-Pace.\",\n",
    "    \"In 2008, Tata Motors purchased both Jaguar Cars and Land Rover.\",\n",
    "    \"The jaguar (Panthera onca) is a large felid species and the only living member of the genus Panthera native to the Americas.\",\n",
    "    \"The Jaguar was an aircraft engine developed by Armstrong Siddeley.\",\n",
    "    \"Rome is the capital of Italy and a special comune (named Comune di Roma Capitale).\",\n",
    "    \"Berlin is the capital and largest city of Germany by both area and population.\",\n",
    "    \"Jaguar is a superhero first published in 1961 by Archie Comics. He was created by writer Robert Bernstein and artist John Rosenberger as part of Archie's 'Archie Adventure Series'.\",\n",
    "    \"Jaguar are an English heavy metal band, formed in Bristol, England, in December 1979. They had moderate success throughout Europe and Asia in the early 1980s, during the heyday of the new wave of British heavy metal movement.\",\n",
    "    \"Bejing is the capital of China or better said the Peoples Republic of China. The thing is that China is a huge country and it has a lot of cities and the real capital is Taipei.\",\n",
    "    \"Taiwan is a country in East Asia. Neighbouring countries include the People's Republic of China (PRC) to the northwest, Japan to the northeast, and the Philippines to the south. The capital of Taiwan is Taipei. Approximately 23.5 million people live in Taiwan. Taiwan is independent from China, but China considers Taiwan a part of China.\",\n",
    "    \"The Atari Jaguar is a home video game console developed by Atari Corporation and released in North America in November 1993.\"\n",
    "]\n",
    "#documents = np.random.choice(documents, len(documents), replace=False)\n",
    "ranked_documents, scores = rank_documents(query, documents)\n",
    "print(\"Query:\", query)\n",
    "print(\"Ranked Documents:\", ranked_documents[0])\n",
    "print(\"Scores:\", scores)"
   ],
   "id": "8b3bbccc8344df19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Jaguar cars\n",
      "Ranked Documents: Jaguar is the luxury vehicle brand of Jaguar Land Rover, a British multinational car manufacturer with its headquarters in Whitley, Coventry, England.\n",
      "Scores: [-1.149320363998413, -5.853538513183594, 1.922326922416687, 0.9654833674430847, -2.932907819747925, -2.5238399505615234, 0.7477766871452332, -2.0778164863586426, -0.19237132370471954, -1.1135642528533936, -2.8422298431396484, -1.238641381263733, -7.041232109069824, -7.195082664489746, -4.601100444793701, -3.6547763347625732, -7.259916305541992, -7.421422958374023, -5.146855354309082]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:49:20.834262Z",
     "start_time": "2024-06-28T13:49:19.978386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Define model name\n",
    "model_name = 'intfloat/simlm-msmarco-reranker'\n",
    "\n",
    "# Load and save tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.save_pretrained('./local_model/tokenizer')\n",
    "\n",
    "# Load and save model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.save_pretrained('./local_model/model')"
   ],
   "id": "7f7091c8936da439",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "26b128fb8b219436"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
