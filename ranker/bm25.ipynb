{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-07T16:20:43.668885Z",
     "start_time": "2024-07-07T16:20:43.665957Z"
    }
   },
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import spacy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import spacy\n",
    "import nltk\n",
    "from transformers import BertTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T17:06:13.140768Z",
     "start_time": "2024-07-07T17:06:11.525360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Tokenizer functions for text processing\n",
    "def tokenizer(doc):\n",
    "    return doc.split()\n",
    "\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "    return [token.text for token in nlp(doc)]\n",
    "\n",
    "\n",
    "def nltk_lemmatizer(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "\n",
    "def bert_subword_tokenizer(tokens):\n",
    "    subwords = []\n",
    "    for token in tokens:\n",
    "        subwords.extend(bert_tokenizer.tokenize(token))\n",
    "    return subwords\n",
    "\n",
    "\n",
    "def combined_tokenizer(doc):\n",
    "    '''\n",
    "    Tokenizes the input document using a combination of spaCy, NLTK, and BERT tokenizers.\n",
    "    :param doc: str: Input document\n",
    "    :return: list: List of subword tokens\n",
    "    '''\n",
    "    spacy_tokens = spacy_tokenizer(doc)\n",
    "\n",
    "    # Step 2: Use NLTK for lemmatization\n",
    "    lemmatized_tokens = nltk_lemmatizer(spacy_tokens)\n",
    "\n",
    "    # Step 3: Use BERT for subword tokenization\n",
    "    bert_tokens = bert_subword_tokenizer(lemmatized_tokens)\n",
    "\n",
    "    return bert_tokens\n",
    "\n",
    "\n",
    "\n",
    "# Base Ranker class\n",
    "class Ranker(ABC):\n",
    "    @abstractmethod\n",
    "    def get_scores(self, query):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        pass\n",
    "\n",
    "    def search(self, query, corpus, n=5):\n",
    "        search1 = set(self.get_top_n(query, corpus, n))\n",
    "        search2 = set(self.get_top_n(query[0].split(\" \"), corpus, n))\n",
    "        return search2.intersection(search1)\n",
    "\n",
    "\n",
    "# BM25 and variants implementation\n",
    "class BM25:\n",
    "    def __init__(self, corpus, tokenizer=None):\n",
    "        self.corpus_size = 0\n",
    "        self.avgdl = 0\n",
    "        self.doc_freqs = []\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        if tokenizer:\n",
    "            corpus = self._tokenize_corpus(corpus)\n",
    "\n",
    "        nd = self._initialize(corpus)\n",
    "        self._calc_idf(nd)\n",
    "\n",
    "    def _initialize(self, corpus):\n",
    "        nd = {}\n",
    "        num_doc = 0\n",
    "        for document in corpus:\n",
    "            self.doc_len.append(len(document))\n",
    "            num_doc += len(document)\n",
    "\n",
    "            frequencies = {}\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.doc_freqs.append(frequencies)\n",
    "\n",
    "            for word, freq in frequencies.items():\n",
    "                try:\n",
    "                    nd[word] += 1\n",
    "                except KeyError:\n",
    "                    nd[word] = 1\n",
    "\n",
    "            self.corpus_size += 1\n",
    "\n",
    "        self.avgdl = num_doc / self.corpus_size\n",
    "        return nd\n",
    "\n",
    "    def _tokenize_corpus(self, corpus):\n",
    "        print('Tokenization successful.')\n",
    "        tokenized_corpus = [self.tokenizer(doc) for doc in corpus]\n",
    "        return tokenized_corpus\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "        scores = self.get_scores(query)\n",
    "        top_n = np.argsort(scores)[::-1][:n]\n",
    "        return [documents[i] for i in top_n]\n",
    "\n",
    "class BM25Okapi(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25, relevance_model=None):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        self.relevance_model = relevance_model\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        idf_sum = 0\n",
    "        negative_idfs = []\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = idf_sum / len(self.idf)\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
    "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        '''\n",
    "        Get the top n documents based on the BM25 score and the relevance score from the neural model.\n",
    "        :param query: list: List of query tokens\n",
    "        :param documents: list: List of documents in the corpus\n",
    "        :param n: int: Number of documents to return\n",
    "        :return: list: List of top n documents\n",
    "        :return: list: List of scores for the top n documents\n",
    "        '''\n",
    "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "        scores = self.get_scores(query)\n",
    "        \n",
    "        # Re-ranking using BERT embedding and cosine similarity\n",
    "        query_tokens = query\n",
    "        query_vec = bert_embedding(' '.join(query_tokens), bert_model, bert_tokenizer)\n",
    "    \n",
    "        combined_scores = []\n",
    "        for idx, score in enumerate(scores):\n",
    "            doc_tokens = documents[idx].split()\n",
    "            token_overlap = soft_token_overlap(query_tokens, doc_tokens)\n",
    "            doc_vec = bert_embedding(documents[idx], bert_model, bert_tokenizer)\n",
    "            similarity = cosine_sim(query_vec, doc_vec)\n",
    "            combined_score = score + token_overlap + similarity\n",
    "            combined_scores.append(combined_score)\n",
    "        \n",
    "        top_n_indices = np.argsort(combined_scores)[::-1][:n]\n",
    "        filtered_docs = []\n",
    "        relevance_scores = []\n",
    "        \n",
    "        # Applying the neural relevance filter\n",
    "        for i in top_n_indices:\n",
    "            features = torch.tensor([combined_scores[i]], dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                relevance_score = self.relevance_model(features).item()\n",
    "            if relevance_score >= 0.7:  # Threshold can be adjusted\n",
    "                filtered_docs.append(documents[i])\n",
    "                relevance_scores.append(relevance_score)\n",
    "            if len(filtered_docs) >= n:\n",
    "                break\n",
    "        \n",
    "        return filtered_docs, relevance_scores\n",
    "\n",
    "class BM25L(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=0.5):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = np.log(self.corpus_size + 1) - np.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            score += (self.idf.get(q) or 0) * (self.k1 + 1) * (ctd + self.delta) / \\\n",
    "                     (self.k1 + ctd + self.delta)\n",
    "        print(f\"Query: {query}, Scores: {score}\")\n",
    "        return score\n",
    "\n",
    "class BM25Plus(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, delta=1):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        for word, freq in nd.items():\n",
    "            idf = math.log(self.corpus_size + 1) - math.log(freq)\n",
    "            self.idf[word] = idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            score += (self.idf.get(q) or 0) * (self.delta + (q_freq * (self.k1 + 1)) /\n",
    "                                               (self.k1 * (1 - self.b + self.b * doc_len / self.avgdl) + q_freq))\n",
    "        print(f\"Query: {query}, Scores: {score}\")\n",
    "        return score\n",
    "\n",
    "class IDFDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features, idf = self.data[idx]\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(idf, dtype=torch.float32)\n",
    "    \n",
    "class RelevanceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features, label = self.data[idx]\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class IDFNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(IDFNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))  # Add bias as a parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x += self.bias\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "class NeuralBM25(BM25):\n",
    "    def __init__(self, corpus, tokenizer=None, idf_model=None, k1=1.5, b=0.75, delta=0.5):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.delta = delta\n",
    "        self.idf_model = idf_model\n",
    "        super().__init__(corpus, tokenizer)\n",
    "\n",
    "    def _calc_idf(self, nd):\n",
    "        # No need to calculate IDF traditionally\n",
    "        pass\n",
    "\n",
    "    def get_idf(self, word_freq):\n",
    "        with torch.no_grad():\n",
    "            features = torch.tensor([word_freq], dtype=torch.float32)\n",
    "            idf = self.idf_model(features).item()\n",
    "        return idf\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        score = np.zeros(self.corpus_size)\n",
    "        doc_len = np.array(self.doc_len)\n",
    "        for q in query:\n",
    "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            idf = self.get_idf(q_freq.mean())  # Using mean frequency for simplicity\n",
    "            score += idf * (self.k1 + 1) * (ctd + self.delta) / (self.k1 + ctd + self.delta)\n",
    "\n",
    "        print(f\"Query: {query}, Scores: {score}\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_batch_scores(self, query, doc_ids):\n",
    "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
    "        score = np.zeros(len(doc_ids))\n",
    "        doc_len = np.array(self.doc_len)[doc_ids]\n",
    "        for q in query:\n",
    "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
    "            ctd = q_freq / (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "            idf = self.get_idf(q_freq.mean())  # Using mean frequency for simplicity\n",
    "            score += idf * (self.k1 + 1) * (ctd + self.delta) / (self.k1 + ctd + self.delta)\n",
    "        return score.tolist()\n",
    "    \n",
    "class RelevanceNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RelevanceNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# StatisticalRanker class to wrap the BM25 variants\n",
    "class StatisticalRanker(Ranker):\n",
    "    def __init__(self, corpus, ranker_type=\"bm25_okapi\", tokenizer=None, **kwargs):\n",
    "        self.corpus = corpus\n",
    "        self.tokenizer = tokenizer or tokenizer\n",
    "        self.ranker = self._initialize_ranker(ranker_type, **kwargs)\n",
    "        self.ranker_name = ranker_type\n",
    "\n",
    "    def _initialize_ranker(self, ranker_type, **kwargs):\n",
    "        if ranker_type != \"neural\" and kwargs.get(\"idf_model\"):\n",
    "            raise ValueError(\"IDF model not required for statistical rankers. Please remove the 'idf_model' argument.\")\n",
    "        if ranker_type == \"bm25_okapi\":\n",
    "            return BM25Okapi(self.corpus, self.tokenizer, **kwargs)\n",
    "        elif ranker_type == \"bm25_plus\":\n",
    "            return BM25Plus(self.corpus, self.tokenizer, **kwargs)\n",
    "        elif ranker_type == \"bm25_l\":\n",
    "            return BM25L(self.corpus, self.tokenizer, **kwargs)\n",
    "        elif ranker_type == \"neural\":\n",
    "            idf_model = kwargs.get(\"idf_model\")\n",
    "            return NeuralBM25(corpus=self.corpus, tokenizer=self.tokenizer, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranker type: {ranker_type}. Valid options are 'bm25_okapi', 'bm25_plus', 'bm25_l', 'neural'.\")\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        return self.ranker.get_scores(query)\n",
    "\n",
    "    def get_top_n(self, query, documents, n=5):\n",
    "        return self.ranker.get_top_n(query, documents, n)\n",
    "\n",
    "\n",
    "# RankerFactory to create rankers\n",
    "class RankerFactory:\n",
    "    @staticmethod\n",
    "    def create_ranker(ranker_type, corpus=None, tokenizer=None, **kwargs):\n",
    "        if ranker_type in ['bm25_okapi', 'bm25_plus', 'bm25_l']:\n",
    "            return StatisticalRanker(corpus, ranker_type=ranker_type, tokenizer=tokenizer, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranker type: {ranker_type}\")\n",
    "\n",
    "\n",
    "\n",
    "# Training data preparation (example)\n",
    "def prepare_training_data(corpus, idf_values):\n",
    "    training_data = []\n",
    "    for word, idf in idf_values.items():\n",
    "        freq = sum([1 for doc in corpus if word in doc])\n",
    "        features = [freq]  # Add more features if necessary\n",
    "        training_data.append((features, idf))\n",
    "    return training_data\n",
    "\n",
    "# Example training process\n",
    "def train_idf_model(training_data, epochs=100, lr=0.001):\n",
    "    dataset = IDFDataset(training_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    model = IDFNet(input_size=len(training_data[0][0]))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for features, idf in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.squeeze(), idf)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_relevance_model(training_data, epochs=100, lr=0.001):\n",
    "    dataset = RelevanceDataset(training_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    model = RelevanceNet(input_size=len(training_data[0][0]))\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for features, label in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_idf(tokenized_corpus):\n",
    "    num_docs = len(tokenized_corpus)\n",
    "    doc_freqs = defaultdict(int)\n",
    "\n",
    "    for doc in tokenized_corpus:\n",
    "        unique_words = set(doc)\n",
    "        for word in unique_words:\n",
    "            doc_freqs[word] += 1\n",
    "\n",
    "    idf_scores = {word: math.log(num_docs / (freq + 1)) + 1 for word, freq in doc_freqs.items()}\n",
    "    return idf_scores\n",
    "\n",
    "\n",
    "def generate_neural_idf_scores(corpus, idf_model, tokenizer):\n",
    "    tokenized_corpus = [tokenizer(doc) for doc in corpus]\n",
    "    word_freqs = defaultdict(int)\n",
    "    for doc in tokenized_corpus:\n",
    "        for word in doc:\n",
    "            word_freqs[word] += 1\n",
    "\n",
    "    neural_idf_scores = {}\n",
    "    for word, freq in word_freqs.items():\n",
    "        features = torch.tensor([[freq]], dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            idf = idf_model(features).item()\n",
    "        neural_idf_scores[word] = idf\n",
    "\n",
    "    return neural_idf_scores\n",
    "\n",
    "\n",
    "def label_corpus_with_idf(corpus_df, neural_idf_scores):\n",
    "    tokenized_corpus = [tokenizer(doc) for doc in corpus_df['text']]\n",
    "    idf_labels = []\n",
    "    for doc in tokenized_corpus:\n",
    "        idf_score = sum(neural_idf_scores[word] for word in doc) / len(doc)  # Average IDF score\n",
    "        idf_labels.append(idf_score)\n",
    "    corpus_df['idf_score'] = idf_labels\n",
    "    \n",
    "    \n",
    "\n",
    "def soft_token_overlap(query_tokens, doc_tokens):\n",
    "    query_set = set(query_tokens)\n",
    "    doc_set = set(doc_tokens)\n",
    "    intersection = query_set.intersection(doc_set)\n",
    "    union = query_set.union(doc_set)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def bert_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "def cosine_sim(query_vec, doc_vec):\n",
    "    return cosine_similarity(query_vec, doc_vec)[0][0]"
   ],
   "id": "7a9f94563640b560",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T16:44:31.489106Z",
     "start_time": "2024-07-07T16:44:31.485652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_df = pd.read_csv('../dummyindex.csv', delimiter=',')\n",
    "corpus = corpus_df['text'].tolist()"
   ],
   "id": "8191095bab457417",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T16:45:23.214401Z",
     "start_time": "2024-07-07T16:45:23.207839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTTokenizerWrapper:\n",
    "    def __init__(self, pretrained_model='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "        self.model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "    def tokenize(self, doc):\n",
    "        inputs = self.tokenizer(doc, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "class BERTTokenizerWrapper:\n",
    "    def __init__(self, pretrained_model='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "    def tokenize(self, doc):\n",
    "        tokens = self.tokenizer.tokenize(doc)\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "def soft_token_overlap(query_tokens, doc_tokens):\n",
    "    query_set = set(query_tokens)\n",
    "    doc_set = set(doc_tokens)\n",
    "    intersection = query_set.intersection(doc_set)\n",
    "    union = query_set.union(doc_set)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def bert_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "def cosine_sim(query_vec, doc_vec):\n",
    "    return cosine_similarity(query_vec, doc_vec)[0][0]"
   ],
   "id": "d5473d8652e77ff3",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T17:08:47.624678Z",
     "start_time": "2024-07-07T17:08:42.602858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def monte_carlo_tuples(n=1000, threshold=0.5, false_negative_rate=0.1, false_positive_rate=0.1):\n",
    "    \"\"\"\n",
    "    Generate tuples using the Monte Carlo method with noise to introduce false negatives and false positives.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): Number of tuples to generate.\n",
    "    threshold (float): Threshold to determine the label. If the score is above the threshold, the label is 1; otherwise, it's 0.\n",
    "    false_negative_rate (float): Probability of labeling a high score as 0.\n",
    "    false_positive_rate (float): Probability of labeling a low score as 1.\n",
    "\n",
    "    Returns:\n",
    "    list: List of tuples where each tuple contains a list of scores and a label.\n",
    "    \"\"\"\n",
    "    tuples = []\n",
    "    for _ in range(n):\n",
    "        score = random.uniform(0, 1)  # Generate a random score between 0 and 1\n",
    "        if score > threshold:\n",
    "            label = 0 if random.random() < false_negative_rate else 1\n",
    "        else:\n",
    "            label = 1 if random.random() < false_positive_rate else 0\n",
    "        tuples.append(([score], label))\n",
    "    return tuples\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    corpus_df = pd.read_csv('../dummyindex.csv', delimiter=',')\n",
    "    corpus = corpus_df['text'].tolist()\n",
    "\n",
    "    # Example training data for relevance model\n",
    "    # make monte carlo data set 0.7 threshold\n",
    "    relevance_training_data = monte_carlo_tuples(n=1000, threshold=0.5, false_negative_rate=0.1, false_positive_rate=0.01)\n",
    "\n",
    "    relevance_model = train_relevance_model(relevance_training_data)\n",
    "\n",
    "    # Test BM25Okapi with combined tokenization and re-ranking with neural filter\n",
    "    ranker = RankerFactory.create_ranker('bm25_okapi', corpus=corpus, tokenizer=combined_tokenizer, relevance_model=relevance_model)\n",
    "    query = combined_tokenizer('Statue of Liberty')\n",
    "    top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "    \n",
    "    print(\"Top Documents:\")\n",
    "    for doc in top_n_documents:\n",
    "        print(doc)\n"
   ],
   "id": "9c9ed541b203b568",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Loss: 0.6251\n",
      "Epoch [10/100], Loss: 0.6653\n",
      "Epoch [20/100], Loss: 0.1153\n",
      "Epoch [30/100], Loss: 0.3903\n",
      "Epoch [40/100], Loss: 0.3548\n",
      "Epoch [50/100], Loss: 0.0890\n",
      "Epoch [60/100], Loss: 0.2853\n",
      "Epoch [70/100], Loss: 0.0829\n",
      "Epoch [80/100], Loss: 0.1401\n",
      "Epoch [90/100], Loss: 0.1958\n",
      "Tokenization successful.\n",
      "Top Documents:\n",
      "['Come to the Statue of Liberty and see the beauty of New York.', 'The Statue of Liberty is a destination for sightseers in New York.', 'The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor in New York City, in the United States.', 'The Statue of Liberty, the Eiffel Tower, the Great Wall of China, the Taj Mahal, the Colosseum, the Great Pyramid of Giza, the Sydney Opera House, the Burj Khalifa, the Petronas Towers, and the Leaning Tower of Pisa are some of the most famous landmarks in the world.', 'Jaguar is a city in the Amazon region of Brazil. The city is the seat of the municipality of Jaguar, in the state of Pará.']\n",
      "[0.983534038066864, 0.9988574981689453, 0.999998927116394, 0.9975365400314331, 0.9709850549697876]\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T16:30:50.368134Z",
     "start_time": "2024-07-07T16:30:48.002743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    # Test BM25Okapi with combined tokenization and re-ranking\n",
    "    ranker = RankerFactory.create_ranker('bm25_okapi', corpus=corpus, tokenizer=combined_tokenizer)\n",
    "    query = combined_tokenizer('Statue of Liberty')\n",
    "    top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "    \n",
    "    print(\"Top Documents:\")\n",
    "    for doc in top_n_documents:\n",
    "        print(doc)\n",
    "\n",
    "    # Test BM25L with spaCy tokenization\n",
    "    ranker = RankerFactory.create_ranker('bm25_l', corpus=corpus, tokenizer=spacy_tokenizer)\n",
    "    query = spacy_tokenizer('Statue of Liberty')\n",
    "    top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "    "
   ],
   "id": "123f4e1593861e06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization successful.\n",
      "Top Documents:\n",
      "Come to the Statue of Liberty and see the beauty of New York.\n",
      "The Statue of Liberty is a destination for sightseers in New York.\n",
      "The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor in New York City, in the United States.\n",
      "The Statue of Liberty, the Eiffel Tower, the Great Wall of China, the Taj Mahal, the Colosseum, the Great Pyramid of Giza, the Sydney Opera House, the Burj Khalifa, the Petronas Towers, and the Leaning Tower of Pisa are some of the most famous landmarks in the world.\n",
      "Jaguar is a city in the Amazon region of Brazil. The city is the seat of the municipality of Jaguar, in the state of Pará.\n",
      "Tokenization successful.\n",
      "Query: ['Statue', 'of', 'Liberty'], Scores: [7.29738011 7.33156948 3.01148463 3.33777877 3.01148463 3.2872123\n",
      " 3.01148463 3.01148463 3.01148463 3.01148463 3.27366858 3.01148463\n",
      " 3.01148463 3.29204328 3.01148463 3.33126266 3.3516415  3.2538287\n",
      " 3.34009449 3.43720197 3.35256732 3.01148463 3.22197276 3.23365438\n",
      " 3.23365438 3.01148463 7.04237121 3.01148463 3.48479129 3.41967288\n",
      " 3.39938844 3.44360835 3.23999529 3.26473618 3.01148463 3.52805244\n",
      " 5.43436998 3.29204328 3.32500171 3.52709372]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T16:25:05.745043Z",
     "start_time": "2024-07-07T16:25:05.694173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_df = pd.read_csv('../dummyindex.csv', delimiter=',')\n",
    "corpus = corpus_df['text'].tolist()\n",
    "\n",
    "# Test BM25Okapi with combined tokenization and re-ranking\n",
    "ranker = RankerFactory.create_ranker('bm25_okapi', corpus=corpus, tokenizer=tokenizer)\n",
    "query = combined_tokenizer('Statue of Liberty')\n",
    "top_n_documents = ranker.get_top_n(query, corpus, n=5)\n",
    "\n",
    "print(\"Top Documents:\")\n",
    "for doc in top_n_documents:\n",
    "    print(doc)"
   ],
   "id": "c5f02e396550ae23",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'tokenize'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m corpus \u001B[38;5;241m=\u001B[39m corpus_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Test BM25Okapi with combined tokenization and re-ranking\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m ranker \u001B[38;5;241m=\u001B[39m \u001B[43mRankerFactory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_ranker\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbm25_okapi\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m query \u001B[38;5;241m=\u001B[39m combined_tokenizer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStatue of Liberty\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m top_n_documents \u001B[38;5;241m=\u001B[39m ranker\u001B[38;5;241m.\u001B[39mget_top_n(query, corpus, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "Cell \u001B[0;32mIn[36], line 327\u001B[0m, in \u001B[0;36mRankerFactory.create_ranker\u001B[0;34m(ranker_type, corpus, tokenizer, **kwargs)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_ranker\u001B[39m(ranker_type, corpus\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, tokenizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ranker_type \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbm25_okapi\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbm25_plus\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbm25_l\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m--> 327\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mStatisticalRanker\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mranker_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mranker_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    329\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown ranker type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mranker_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[36], line 297\u001B[0m, in \u001B[0;36mStatisticalRanker.__init__\u001B[0;34m(self, corpus, ranker_type, tokenizer, **kwargs)\u001B[0m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorpus \u001B[38;5;241m=\u001B[39m corpus\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer \u001B[38;5;241m=\u001B[39m tokenizer \u001B[38;5;129;01mor\u001B[39;00m tokenizer\n\u001B[0;32m--> 297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mranker \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize_ranker\u001B[49m\u001B[43m(\u001B[49m\u001B[43mranker_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mranker_name \u001B[38;5;241m=\u001B[39m ranker_type\n",
      "Cell \u001B[0;32mIn[36], line 304\u001B[0m, in \u001B[0;36mStatisticalRanker._initialize_ranker\u001B[0;34m(self, ranker_type, **kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIDF model not required for statistical rankers. Please remove the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124midf_model\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ranker_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbm25_okapi\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBM25Okapi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m ranker_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbm25_plus\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m BM25Plus(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorpus, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Cell \u001B[0;32mIn[36], line 126\u001B[0m, in \u001B[0;36mBM25Okapi.__init__\u001B[0;34m(self, corpus, tokenizer, k1, b, epsilon)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb \u001B[38;5;241m=\u001B[39m b\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepsilon \u001B[38;5;241m=\u001B[39m epsilon\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[36], line 72\u001B[0m, in \u001B[0;36mBM25.__init__\u001B[0;34m(self, corpus, tokenizer)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer \u001B[38;5;241m=\u001B[39m tokenizer\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tokenizer:\n\u001B[0;32m---> 72\u001B[0m     corpus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenize_corpus\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m nd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize(corpus)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calc_idf(nd)\n",
      "Cell \u001B[0;32mIn[36], line 103\u001B[0m, in \u001B[0;36mBM25._tokenize_corpus\u001B[0;34m(self, corpus)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_tokenize_corpus\u001B[39m(\u001B[38;5;28mself\u001B[39m, corpus):\n\u001B[0;32m--> 103\u001B[0m     tokenized_corpus \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenized_corpus\n",
      "Cell \u001B[0;32mIn[36], line 103\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_tokenize_corpus\u001B[39m(\u001B[38;5;28mself\u001B[39m, corpus):\n\u001B[0;32m--> 103\u001B[0m     tokenized_corpus \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m(doc) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m corpus]\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenized_corpus\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'tokenize'"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenized_corpus_default = [tokenizer(doc) for doc in corpus]\n",
    "tokenized_corpus_combined = [combined_tokenizer(doc) for doc in corpus]\n",
    "default = set([word for doc in tokenized_corpus_default for word in doc])\n",
    "combined = set([word for doc in tokenized_corpus_combined for word in doc])\n",
    "\n",
    "len(default.union(combined) - default.intersection(combined) - default), len(default.union(combined) - default.intersection(combined) - combined)"
   ],
   "id": "4125e2a205a94351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ranker = RankerFactory.create_ranker('bm25_okapi', corpus=tokenized_corpus_default, tokenizer=None)\n",
    "top_n_documents = ranker.get_top_n(query, tokenized_corpus_default, n=5)\n",
    "ranker = RankerFactory.create_ranker('bm25_okapi', corpus=tokenized_corpus_default, tokenizer=None)\n",
    "top_n_documents = ranker.get_top_n(query, tokenized_corpus_default, n=5)"
   ],
   "id": "6ef5d99396d3e83f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1ca9739baeb39070",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
